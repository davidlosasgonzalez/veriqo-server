# ü§ñ Modelos LLM y Decisiones T√©cnicas ‚Äì Veriqo

Este documento resume las decisiones arquitect√≥nicas y operativas que sustentan el uso de modelos de lenguaje (LLM) en el sistema Veriqo.

## üß† Modelos utilizados en Veriqo

| Agente           | Modelo LLM             | Proveedor | Finalidad principal                                        |
| ---------------- | ---------------------- | --------- | ---------------------------------------------------------- |
| ValidatorAgent   | Claude 3.5 Sonnet      | Anthropic | Evaluaci√≥n contextual, detecci√≥n de ambig√ºedades o errores |
| FactCheckerAgent | GPT-4o                 | OpenAI    | S√≠ntesis de evidencia y emisi√≥n de veredictos factuales    |
| Embeddings       | text-embedding-3-small | OpenAI    | Normalizaci√≥n sem√°ntica y deduplicaci√≥n de afirmaciones    |

> üß™ Esta combinaci√≥n fue definida tras pruebas comparativas, priorizando latencia baja, coste por token y calidad contextual.

## üîç Criterios t√©cnicos de selecci√≥n

Las decisiones han sido guiadas por:

- **Comprensi√≥n contextual avanzada**: imprescindible para evaluar veracidad, contradicci√≥n o ambig√ºedad.
- **Rendimiento / latencia**: se exige rapidez para mantener la experiencia del usuario fluida.
- **Coste eficiente**: Claude 3.5 se elige por su buen balance coste/calidad para tareas de validaci√≥n inicial.
- **Integraci√≥n limpia con Node.js**: todos los modelos se consumen v√≠a API HTTP desde `AiRouterService`.

## üß© Sistema de ruteo inteligente (`AiRouterService`)

Veriqo centraliza la selecci√≥n y consumo de modelos mediante un servicio inteligente:

- Permite cambiar el modelo por agente desde `.env` (`LLM_VALIDATOR_MODEL`, `LLM_FACTCHECKER_MODEL`).
- A√≠sla la l√≥gica de cada agente respecto a la implementaci√≥n del modelo.
- Facilita la extensi√≥n futura hacia nuevos modelos o proveedores.

## ‚ôªÔ∏è Posibilidades de evoluci√≥n

- Soporte para **modelos locales** mediante Ollama o LM Studio (en pausa por ahora).
- Embeddings alternativos open source (`bge-small`, `e5-base`, etc.).
- Clasificaci√≥n previa para elegir autom√°ticamente el mejor modelo seg√∫n el tipo de afirmaci√≥n.

### üîÑ Modelos descartados en pruebas

Durante el desarrollo se evaluaron localmente:

- **Mistral-7B**, **DeepSeek**, **TinyLlama**, etc.

Fueron descartados temporalmente por:

- Latencia elevada (>30s incluso en CPU moderna).
- Altos requisitos de memoria sin aceleraci√≥n GPU.
- Rendimiento pobre en prompts complejos sin fine-tuning.

> ‚ö†Ô∏è El equipo de desarrollo utiliza un port√°til con 16‚ÄØGB de RAM y sin GPU dedicada. Por ese motivo, los modelos locales provocaban una degradaci√≥n importante de latencia, por lo que se prioriz√≥ el uso de APIs externas. Sin embargo, otros desarrolladores con hardware m√°s potente pueden experimentar mejores resultados con modelos locales.

## üõ°Ô∏è Consideraciones de seguridad y trazabilidad

- No se env√≠a informaci√≥n sensible en prompts a modelos externos.
- Todas las llamadas son as√≠ncronas y registradas con trazabilidad completa.
- Todas las respuestas generadas por los agentes se registran con trazabilidad completa en `agent_logs`, incluyendo el modelo, prompt, resultado, tokens y tiempo de ejecuci√≥n.

## üìÅ Archivos relacionados

- `src/shared/ai/ai-router.service.ts`
- `.env` (`LLM_*`)
- `src/agents/*/*.agent.service.ts`
- `src/database/entities/agent-log.entity.ts`
