# ğŸ¤– Modelos LLM y Decisiones TÃ©cnicas â€“ Veriqo

Este documento resume las decisiones arquitectÃ³nicas y operativas que sustentan el uso de modelos de lenguaje (LLM) en el sistema Veriqo.

## ğŸ§  Modelos utilizados en Veriqo

| Agente           | Modelo LLM             | Proveedor | Finalidad principal                                        |
| ---------------- | ---------------------- | --------- | ---------------------------------------------------------- |
| ValidatorAgent   | Claude 3.5 Sonnet      | Anthropic | EvaluaciÃ³n contextual, detecciÃ³n de ambigÃ¼edades o errores |
| FactCheckerAgent | GPT-4o                 | OpenAI    | SÃ­ntesis de evidencia y emisiÃ³n de veredictos factuales    |
| Embeddings       | text-embedding-3-small | OpenAI    | NormalizaciÃ³n semÃ¡ntica y deduplicaciÃ³n de afirmaciones    |

> ğŸ§ª Esta combinaciÃ³n fue definida tras pruebas comparativas, priorizando latencia baja, coste por token y calidad contextual.

## ğŸ” Criterios tÃ©cnicos de selecciÃ³n

Las decisiones han sido guiadas por:

- **ComprensiÃ³n contextual avanzada**: imprescindible para evaluar veracidad, contradicciÃ³n o ambigÃ¼edad.
- **Rendimiento / latencia**: se exige rapidez para mantener la experiencia del usuario fluida.
- **Coste eficiente**: Claude 3.5 se elige por su buen balance coste/calidad para tareas de validaciÃ³n inicial.
- **IntegraciÃ³n limpia con Node.js**: todos los modelos se consumen vÃ­a API HTTP desde `AiRouterService`.

## ğŸ§¹ Sistema de ruteo inteligente (`AiRouterService`)

Veriqo centraliza la selecciÃ³n y consumo de modelos mediante un servicio inteligente:

- Permite cambiar el modelo por agente desde `.env` (`LLM_VALIDATOR_MODEL`, `LLM_FACTCHECKER_MODEL`).
- AÃ­sla la lÃ³gica de cada agente respecto a la implementaciÃ³n del modelo.
- Facilita la extensiÃ³n futura hacia nuevos modelos o proveedores.

## â™»ï¸ Posibilidades de evoluciÃ³n

- Soporte para **modelos locales** mediante Ollama o LM Studio (en pausa por ahora).
- Embeddings alternativos open source (`bge-small`, `e5-base`, etc.).
- ClasificaciÃ³n previa para elegir automÃ¡ticamente el mejor modelo segÃºn el tipo de afirmaciÃ³n.

### â†º Modelos descartados en pruebas

Durante el desarrollo se evaluaron localmente:

- **Mistral-7B**, **DeepSeek**, **TinyLlama**, etc.

Fueron descartados temporalmente por:

- Latencia elevada (>30s incluso en CPU moderna).
- Altos requisitos de memoria sin aceleraciÃ³n GPU.
- Rendimiento pobre en prompts complejos sin fine-tuning.

> âš ï¸ El equipo de desarrollo utiliza un portÃ¡til con 16â€‰GB de RAM y sin GPU dedicada. Por ese motivo, los modelos locales provocaban una degradaciÃ³n importante de latencia, por lo que se priorizÃ³ el uso de APIs externas. Sin embargo, otros desarrolladores con hardware mÃ¡s potente pueden experimentar mejores resultados con modelos locales.

## ğŸ›¡ï¸ Consideraciones de seguridad y trazabilidad

- No se envÃ­a informaciÃ³n sensible en prompts a modelos externos.
- Todas las llamadas son asÃ­ncronas y registradas con trazabilidad completa.
- Todas las respuestas generadas por los agentes se registran con trazabilidad completa en `agent_logs`, incluyendo el modelo, prompt, resultado, tokens y tiempo de ejecuciÃ³n.

## ğŸ“ Archivos relacionados

- `src/shared/ai/ai-router.service.ts`
- `.env` (`LLM_*`)
- `src/agents/*/*.agent.service.ts`
- `src/database/entities/agent-log.entity.ts`
